# -*- coding: utf-8 -*-
"""CSCE5290-ICE-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CnP_e5vsN8OqT-MbI4XgIFfk3s1cQUla
"""

# import nltk
# nltk.download('stopwords')

import urllib.request
response = urllib.request.urlopen('http://en.wikipedia.org/wiki/SpaceX')
html = response.read()
print(html)

from bs4 import BeautifulSoup

import urllib.request

import nltk

from nltk.corpus import stopwords

response = urllib.request.urlopen('http://en.wikipedia.org/wiki/SpaceX')

html = response.read()

soup = BeautifulSoup(html,"html5lib")

text = soup.get_text(strip=True)

print(text)

# tt will hold the words with 5 or more in frequency
tt = []
tokens = [t for t in text.split()]
print("Number of tokens before clean up: ", len(tokens))

freq1 = nltk.FreqDist(tokens[:])
for k,v in freq1.items():
  if v >= 5:
    for i in range(v):
      tt.append(k)

print("Number of tokens after clean up: ", len(tt))

clean_tokens = tt[:]

sr = stopwords.words('english')

for token in tt:
    if token in sr:
        clean_tokens.remove(token)

freq1 = nltk.FreqDist(tt[:])
freq2 = nltk.FreqDist(clean_tokens)


# All tokens
for key,val in freq1.items():
    if val >= 5:
      print(str(key) + ':' + str(val))

# Clean Tokens
for key,val in freq2.items():
    if val >= 5:
      print(str(key) + ':' + str(val))

print("All Tokens")
freq1.plot(10, cumulative=False)

"""# New Section"""

print("Clean Tokens")
freq2.plot(10, cumulative=False)

# With Stopwords
freq1.tabulate(10, cumulative=False)

# Without Stopwords
freq2.tabulate(10, cumulative=False)
